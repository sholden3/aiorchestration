name: Test Suite

on:
  push:
    branches: [ main, develop ]
  pull_request:
    branches: [ main ]
  schedule:
    # Run tests daily at 2 AM UTC
    - cron: '0 2 * * *'

env:
  PYTHON_VERSION: '3.11'
  NODE_VERSION: '18'
  GOVERNANCE_BYPASS: true
  TESTING: true

jobs:
  # Python Backend Tests
  backend-tests:
    name: Backend Tests (Python)
    runs-on: ubuntu-latest
    
    services:
      postgres:
        image: postgres:14
        env:
          POSTGRES_USER: test
          POSTGRES_PASSWORD: test
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432
      
      redis:
        image: redis:7
        options: >-
          --health-cmd "redis-cli ping"
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 6379:6379

    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
        cache: 'pip'
    
    - name: Install Python dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pytest pytest-cov pytest-asyncio pytest-benchmark
        if [ -f ai-assistant/backend/requirements.txt ]; then 
          pip install -r ai-assistant/backend/requirements.txt
        fi
        if [ -f governance/requirements.txt ]; then
          pip install -r governance/requirements.txt
        fi
    
    - name: Run Backend Tests
      env:
        DATABASE_URL: postgresql://test:test@localhost:5432/test_db
        REDIS_URL: redis://localhost:6379/0
      run: |
        cd ai-assistant/backend
        python -m pytest tests/ -v --cov=. --cov-report=xml --cov-report=term
    
    - name: Run Governance Tests
      run: |
        cd governance
        python -m pytest tests/ -v --cov=. --cov-report=xml --cov-report=term
    
    - name: Upload Backend Coverage
      uses: codecov/codecov-action@v3
      with:
        file: ./ai-assistant/backend/coverage.xml
        flags: backend
        name: backend-coverage
    
    - name: Upload Governance Coverage
      uses: codecov/codecov-action@v3
      with:
        file: ./governance/coverage.xml
        flags: governance
        name: governance-coverage

  # TypeScript/Angular Frontend Tests
  frontend-tests:
    name: Frontend Tests (Angular/TypeScript)
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
        cache: 'npm'
        cache-dependency-path: ai-assistant/package-lock.json
    
    - name: Install dependencies
      run: |
        cd ai-assistant
        npm ci
    
    - name: Run linting
      run: |
        cd ai-assistant
        npm run lint || true  # Don't fail on lint errors yet
    
    - name: Run Frontend Tests
      run: |
        cd ai-assistant
        npm test -- --watch=false --browsers=ChromeHeadless --code-coverage
    
    - name: Upload Frontend Coverage
      uses: codecov/codecov-action@v3
      with:
        file: ./ai-assistant/coverage/lcov.info
        flags: frontend
        name: frontend-coverage

  # Integration Tests
  integration-tests:
    name: Integration Tests
    runs-on: ubuntu-latest
    needs: [backend-tests, frontend-tests]
    
    services:
      postgres:
        image: postgres:14
        env:
          POSTGRES_USER: test
          POSTGRES_PASSWORD: test
          POSTGRES_DB: test_db
        options: >-
          --health-cmd pg_isready
          --health-interval 10s
          --health-timeout 5s
          --health-retries 5
        ports:
          - 5432:5432

    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Set up Node.js
      uses: actions/setup-node@v4
      with:
        node-version: ${{ env.NODE_VERSION }}
    
    - name: Install dependencies
      run: |
        # Python dependencies
        python -m pip install --upgrade pip
        pip install pytest pytest-asyncio requests
        if [ -f ai-assistant/backend/requirements.txt ]; then
          pip install -r ai-assistant/backend/requirements.txt
        fi
        
        # Node dependencies
        cd ai-assistant
        npm ci
    
    - name: Start Backend Server
      env:
        DATABASE_URL: postgresql://test:test@localhost:5432/test_db
      run: |
        cd ai-assistant/backend
        python main.py &
        sleep 10  # Wait for server to start
    
    - name: Run Integration Tests
      run: |
        # Add integration tests here
        curl -f http://localhost:8000/health || exit 1
        curl -f http://localhost:8000/api/status || exit 1

  # Security Scanning
  security-scan:
    name: Security Scan
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Run Trivy vulnerability scanner
      uses: aquasecurity/trivy-action@master
      with:
        scan-type: 'fs'
        scan-ref: '.'
        format: 'sarif'
        output: 'trivy-results.sarif'
    
    - name: Upload Trivy results to GitHub Security
      uses: github/codeql-action/upload-sarif@v2
      if: always()
      with:
        sarif_file: 'trivy-results.sarif'
    
    - name: Python Safety Check
      run: |
        pip install safety
        safety check --json || true  # Don't fail build on vulnerabilities yet

  # Code Quality
  code-quality:
    name: Code Quality
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install quality tools
      run: |
        pip install black isort flake8 mypy pylint
    
    - name: Check Python formatting with Black
      run: |
        black --check . || true  # Don't fail on format issues yet
    
    - name: Check import sorting with isort
      run: |
        isort --check-only . || true
    
    - name: Run flake8 linting
      run: |
        flake8 . --count --select=E9,F63,F7,F82 --show-source --statistics || true
    
    - name: Run mypy type checking
      run: |
        mypy . --ignore-missing-imports || true

  # Governance Validation
  governance-check:
    name: Governance Validation
    runs-on: ubuntu-latest
    
    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python
      uses: actions/setup-python@v4
      with:
        python-version: ${{ env.PYTHON_VERSION }}
    
    - name: Install governance dependencies
      run: |
        pip install pyyaml
    
    - name: Run Governance Checks
      run: |
        python governance/validators/domain_validators.py . || true
        python governance/validators/relaxed_document_validator.py || true
    
    - name: Check for magic variables
      run: |
        python governance/core/enhanced_governance_engine.py --check-magic . || true
    
    - name: Check documentation
      run: |
        # Check for missing documentation headers
        find . -name "*.py" -o -name "*.ts" | while read file; do
          if ! grep -q "@fileoverview\|@author" "$file" 2>/dev/null; then
            echo "Warning: $file missing documentation header"
          fi
        done

  # Test Summary
  test-summary:
    name: Test Summary
    runs-on: ubuntu-latest
    needs: [backend-tests, frontend-tests, integration-tests]
    if: always()
    
    steps:
    - name: Test Results Summary
      run: |
        echo "## Test Suite Summary"
        echo "Backend Tests: ${{ needs.backend-tests.result }}"
        echo "Frontend Tests: ${{ needs.frontend-tests.result }}"
        echo "Integration Tests: ${{ needs.integration-tests.result }}"
        
        if [ "${{ needs.backend-tests.result }}" != "success" ] || \
           [ "${{ needs.frontend-tests.result }}" != "success" ] || \
           [ "${{ needs.integration-tests.result }}" != "success" ]; then
          echo "❌ Some tests failed"
          exit 1
        else
          echo "✅ All tests passed"
        fi